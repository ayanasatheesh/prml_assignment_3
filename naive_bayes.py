# -*- coding: utf-8 -*-
"""naive_bayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JfeELJ2puhbZ4PAtzgQSMExKsn4yiiFQ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import pprint
import matplotlib.pyplot as plt

# %matplotlib inline
#%precision 4
#np.set_printoptions(precision=4)
import pylab as pl

from google.colab import drive
drive.mount("/content/gdrive")

import os

from pickle import FALSE
import string
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

def makeDictionary(emails): 

  count={}
  for email in emails:
    #text cleaning
    f=open(email,encoding='latin-1')
    text=f.read()
  
    text_temp = [w for w in text if w not in string.punctuation]
    text_temp = ''.join(text_temp)
   
    content_without_stopwords = [w for w in text_temp.split() if w.lower() not in stopwords.words('english')]
    content_without_stopwords = ' '.join(content_without_stopwords)
    final_text = [w.lower() for w in content_without_stopwords.split()]
    words=final_text
    for word in words:
      x=0
      for c in word:
        x+=1
      if(word.isdigit()==False and x>2):
        if word in count:
          count[word] += 1
        else:
          count[word] = 1

  temp=[]
  for key in count:
    temp.append(key)

  temp.sort()
    

  return temp

def countFrequency(emails,mydict):
  mylist=[]
  ylist=[]
  p1=np.zeros(len(mydict))
  p0=np.zeros(len(mydict))
  total1=0
  total0=0

  for email in emails:
    f=open(email,encoding='latin-1')
    content=f.read()
    words=content.split(" ")
    row = {key: 0 for key in mydict}
    text=content
    text_temp = [w for w in text if w not in string.punctuation]
    text_temp = ''.join(text_temp)
    final_text = [w.lower() for w in text_temp.split()]

    words=final_text
    for word in words:
      if word in mydict:
        row[word]+=1

    rowlist=list(row.values())
    
    mylist.append(rowlist)


    if 'spam' in email:
      ylist.append(1)
      total1+=1
      p1+=rowlist


    if 'ham' in email:
      ylist.append(0)
      total0+=1
      p0+=rowlist


  sum1=np.sum(mylist,axis=1)

  tot1=0
  tot0=0
  #counting the total number of words in spam and nonspam
  for i in range(len(ylist)):
    if(ylist[i]==1):
      tot1+=sum1[i]
    else:
      tot0+=sum1[i]

  p1=(p1+np.ones(len(p1)))/tot1
  p0=(p0+np.ones(len(p0)))/tot0


  t_1=0
  t_0=0
  #counting the no. of spam emails and non spam emails
  for i in range(len(ylist)):
    if(ylist[i]==1):
      t_1+=1
    else:
      t_0+=1
  pspam=t_1/len(emails)
  pnonspam=t_0/len(emails)
  return(p1,p0,pspam,pnonspam)

def learn():
  folder="/content/gdrive/My Drive/Colab Notebooks/emails"
  files=os.listdir(folder)
  emails=[folder+"/"+file for file in files]
  emails=emails[:5712]
  dataset=emails
  train_emails=emails[0:4569]
  test_emails=emails[4569:5000]
  emails=train_emails

  mydict=makeDictionary(emails)

  (p1,p0,pspam,pnonspam)=countFrequency(emails,mydict)

  return(p1,p0,mydict,pspam,pnonspam)

def write4(f,x):
  import pickle
  pickle.dump(x,f)
  f.close()

def writeFiles(p1,p0,pspam,pnonspam,mydict):
  f=open("dictionary.dat","wb")
  write4(f,mydict)
  f=open("spamModel.dat","wb")
  write4(f,p1)
  f=open("nonspamModel.dat","wb")
  write4(f,p0)

  f=open("countspam.dat","wb")
  write4(f,pspam)
  f=open("countnonspam.dat","wb")
  write4(f,pnonspam)

#(p1,p0,mydict,pspam,pnonspam)=learn()

#writeFiles(p1,p0,pspam,pnonspam,mydict)

import pickle

def test(folder):

  files=os.listdir(folder)
  test_emails=[folder+"/"+file for file in files]
  #slicing if required
  #test_emails=test_emails[:5712]
  
  
  #slicing if required
  #test_emails=test_emails[4569:5000]
  
  
  with open('dictionary.dat' , 'rb') as f:
      mydict = pickle.load(f)

  with open('spamModel.dat' , 'rb') as f:
      p1 = pickle.load(f)

  with open('nonspamModel.dat' , 'rb') as f:
      p0 = pickle.load(f)

  with open('countspam.dat' , 'rb') as f:
      pspam = pickle.load(f)

  with open('countnonspam.dat' , 'rb') as f:
      pnonspam = pickle.load(f)

  predcited_ylist=[]
  t1=0
  t0=0
  y_list=[]
  for email in test_emails:
    f=open(email,encoding='latin-1')
    content=f.read()
    words=content.split(" ")
    row = {key: 0 for key in mydict}
    text=content
    content_without_punctuation = [w for w in text if w not in string.punctuation]
    content_without_punctuation = ''.join(content_without_punctuation)
    final_text = [w.lower() for w in content_without_punctuation.split()]

    py1=1
    py0=1
    words=final_text
    for word in words:
      if word in mydict:
        row[word]+=1
    
    rowlist=list(row.values())
    
    for i in range(len(rowlist)):
      py1*=(p1[i]**rowlist[i])
      py0*=(p0[i]**rowlist[i])


    py1*=pspam
    py0*=pnonspam

    if(py1>py0):
      predcited_ylist.append(1)

    else:
      predcited_ylist.append(0)


    if 'spam' in email:
      y_list.append(1)
      t1+=1
     


    if 'ham' in email:
      y_list.append(0)
      t0+=1

  #calculating accuracy
  c1=0
  c0=0
  for i in range(len(y_list)):
    if(predcited_ylist[i]==y_list[i] and y_list[i]==1):
      c1+=1

    if(predcited_ylist[i]==y_list[i] and y_list[i]==0):
      c0+=1

  accuracy_spam=c1/t1
  accuracy_ham=c0/t0
  accuracy_tot=(c1+c0)/(len(y_list))
  print("Total Acccuracy of the model: ",accuracy_tot*100)
  print("Accuracy on spam data: ",accuracy_spam*100)
  print("Accuracy on non spam data:",accuracy_ham*100)

path="test/"
#path="/content/gdrive/My Drive/Colab Notebooks/emails"
test(path)